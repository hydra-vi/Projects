{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.8.0 (from versions: 2.0.0, 2.0.1, 2.1.0)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.8.0\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#install important Libraries\n",
    "%pip install torch==1.8.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'FRS' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n FRS ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#import Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import gdown\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import accuracy, top_k_accuracy\n",
    "from annoy import AnnoyIndex\n",
    "import zipfile\n",
    "import time\n",
    "#from google.colab import drive\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the images\n",
    "root_path = './'\n",
    "#url = 'https://drive.google.com/uc?id=1j5fCPgh0gnY6v7ChkWlgnnHH6unxuAbb'\n",
    "#output = 'img.zip'\n",
    "#gdown.download(url, output, quiet=False)\n",
    "#with zipfile.ZipFile(\"img.zip\",\"r\") as zip_ref:\n",
    "   # zip_ref.extractall(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_list = []\n",
    "image_path_list = []\n",
    "data_type_list = []\n",
    "\n",
    "# category names\n",
    "with open('list_category_cloth.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            category_list.append(line.split(' ')[0])\n",
    "\n",
    "# category map\n",
    "with open('list_category_img.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            image_path_list.append([word.strip() for word in line.split(' ') if len(word) > 0])\n",
    "\n",
    "# train, valid, test\n",
    "with open('list_eval_partition.txt', 'r') as f:\n",
    "    for i, line in enumerate(f.readlines()):\n",
    "        if i > 1:\n",
    "            data_type_list.append([word.strip() for word in line.split(' ') if len(word) > 0])\n",
    "\n",
    "data_df = pd.DataFrame(image_path_list, columns=['image_path', 'category_number'])\n",
    "data_df['category_number'] = data_df['category_number'].astype(int)\n",
    "data_df = data_df.merge(pd.DataFrame(data_type_list, columns=['image_path', 'dataset_type']), on='image_path')\n",
    "data_df['category'] = data_df['category_number'].apply(lambda x: category_list[int(x) - 1])\n",
    "data_df = data_df.drop('category_number', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hydra/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/basic_data.py:262: UserWarning: There seems to be something wrong with your dataset, for example, in the first batch can't access these elements in self.train_ds: 152746,176875,153915,1137,207649...\n",
      "  warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You can deactivate this warning by passing `no_check=True`.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "This function was deprecated since version 1.9 and is now removed. `torch.solve` is deprecated in favor of `torch.linalg.solve`. `torch.linalg.solve` has its arguments reversed and does not return the LU factorization.\n\nTo get the LU factorization see `torch.lu`, which can be used with `torch.lu_solve` or `torch.lu_unpack`.\nX = torch.solve(B, A).solution should be replaced with:\nX = torch.linalg.solve(A, B)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hydra/Desktop/Projects/Machine Learning Projects/Fashion Recommendation System with ML/Notebook.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hydra/Desktop/Projects/Machine%20Learning%20Projects/Fashion%20Recommendation%20System%20with%20ML/Notebook.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data \u001b[39m=\u001b[39m train_image_list\u001b[39m.\u001b[39mtransform(get_transforms(), size\u001b[39m=\u001b[39m\u001b[39m224\u001b[39m)\u001b[39m.\u001b[39mdatabunch(bs\u001b[39m=\u001b[39m\u001b[39m128\u001b[39m)\u001b[39m.\u001b[39mnormalize(imagenet_stats)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hydra/Desktop/Projects/Machine%20Learning%20Projects/Fashion%20Recommendation%20System%20with%20ML/Notebook.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m data\u001b[39m.\u001b[39madd_test(test_image_list)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hydra/Desktop/Projects/Machine%20Learning%20Projects/Fashion%20Recommendation%20System%20with%20ML/Notebook.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data\u001b[39m.\u001b[39mshow_batch(rows\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m8\u001b[39m,\u001b[39m8\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/basic_data.py:186\u001b[0m, in \u001b[0;36mDataBunch.show_batch\u001b[0;34m(self, rows, ds_type, reverse, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshow_batch\u001b[39m(\u001b[39mself\u001b[39m, rows:\u001b[39mint\u001b[39m\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, ds_type:DatasetType\u001b[39m=\u001b[39mDatasetType\u001b[39m.\u001b[39mTrain, reverse:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mShow a batch of data in `ds_type` on a few `rows`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 186\u001b[0m     x,y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mone_batch(ds_type, \u001b[39mTrue\u001b[39;00m, \u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    187\u001b[0m     \u001b[39mif\u001b[39;00m reverse: x,y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflip(\u001b[39m0\u001b[39m),y\u001b[39m.\u001b[39mflip(\u001b[39m0\u001b[39m)\n\u001b[1;32m    188\u001b[0m     n_items \u001b[39m=\u001b[39m rows \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrain_ds\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39m_square_show \u001b[39melse\u001b[39;00m rows\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/basic_data.py:169\u001b[0m, in \u001b[0;36mDataBunch.one_batch\u001b[0;34m(self, ds_type, detach, denorm, cpu)\u001b[0m\n\u001b[1;32m    167\u001b[0m w \u001b[39m=\u001b[39m dl\u001b[39m.\u001b[39mnum_workers\n\u001b[1;32m    168\u001b[0m dl\u001b[39m.\u001b[39mnum_workers \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 169\u001b[0m \u001b[39mtry\u001b[39;00m:     x,y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(dl))\n\u001b[1;32m    170\u001b[0m \u001b[39mfinally\u001b[39;00m: dl\u001b[39m.\u001b[39mnum_workers \u001b[39m=\u001b[39m w\n\u001b[1;32m    171\u001b[0m \u001b[39mif\u001b[39;00m detach: x,y \u001b[39m=\u001b[39m to_detach(x,cpu\u001b[39m=\u001b[39mcpu),to_detach(y,cpu\u001b[39m=\u001b[39mcpu)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/basic_data.py:75\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     74\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mProcess and returns items from `DataLoader`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 75\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdl: \u001b[39myield\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproc_batch(b)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_fetcher\u001b[39m.\u001b[39mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/data_block.py:658\u001b[0m, in \u001b[0;36mLabelList.__getitem__\u001b[0;34m(self, idxs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[39melse\u001b[39;00m:                 x,y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem   ,\u001b[39m0\u001b[39m\n\u001b[1;32m    657\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfmargs:\n\u001b[0;32m--> 658\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mapply_tfms(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfmargs)\n\u001b[1;32m    659\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtfms_y\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfm_y \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    660\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mapply_tfms(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfms_y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfmargs_y, \u001b[39m'\u001b[39m\u001b[39mdo_resolve\u001b[39m\u001b[39m'\u001b[39m:\u001b[39mFalse\u001b[39;00m})\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/image.py:123\u001b[0m, in \u001b[0;36mImage.apply_tfms\u001b[0;34m(self, tfms, do_resolve, xtra, size, resize_method, mult, padding_mode, mode, remove_out)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[39mif\u001b[39;00m resize_method \u001b[39min\u001b[39;00m (ResizeMethod\u001b[39m.\u001b[39mCROP,ResizeMethod\u001b[39m.\u001b[39mPAD):\n\u001b[1;32m    122\u001b[0m             x \u001b[39m=\u001b[39m tfm(x, size\u001b[39m=\u001b[39m_get_crop_target(size,mult\u001b[39m=\u001b[39mmult), padding_mode\u001b[39m=\u001b[39mpadding_mode)\n\u001b[0;32m--> 123\u001b[0m     \u001b[39melse\u001b[39;00m: x \u001b[39m=\u001b[39m tfm(x)\n\u001b[1;32m    124\u001b[0m \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39mrefresh()\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/image.py:524\u001b[0m, in \u001b[0;36mRandTransform.__call__\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x:Image, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39mImage:\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mRandomly execute our tfm on `x`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 524\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtfm(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresolved, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs}) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdo_run \u001b[39melse\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/image.py:470\u001b[0m, in \u001b[0;36mTransform.__call__\u001b[0;34m(self, p, is_random, use_on_y, *args, **kwargs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs:Any, p:\u001b[39mfloat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, is_random:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, use_on_y:\u001b[39mbool\u001b[39m\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs:Any)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39mImage:\n\u001b[1;32m    469\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mCalc now if `args` passed; else create a transform called prob `p` if `random`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 470\u001b[0m     \u001b[39mif\u001b[39;00m args: \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcalc(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    471\u001b[0m     \u001b[39melse\u001b[39;00m: \u001b[39mreturn\u001b[39;00m RandTransform(\u001b[39mself\u001b[39m, kwargs\u001b[39m=\u001b[39mkwargs, is_random\u001b[39m=\u001b[39mis_random, use_on_y\u001b[39m=\u001b[39muse_on_y, p\u001b[39m=\u001b[39mp)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/image.py:475\u001b[0m, in \u001b[0;36mTransform.calc\u001b[0;34m(self, x, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalc\u001b[39m(\u001b[39mself\u001b[39m, x:Image, \u001b[39m*\u001b[39margs:Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs:Any)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39mImage:\n\u001b[1;32m    474\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mApply to image `x`, wrapping it if necessary.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap: \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wrap)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m     \u001b[39melse\u001b[39;00m:          \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc(x, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/image.py:177\u001b[0m, in \u001b[0;36mImage.coord\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcoord\u001b[39m(\u001b[39mself\u001b[39m, func:CoordFunc, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\u001b[39m-\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m\u001b[39mImage\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    176\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mEquivalent to `image.flow = func(image.flow, image.size)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 177\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mflow, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    178\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/transform.py:279\u001b[0m, in \u001b[0;36m_symmetric_warp\u001b[0;34m(c, magnitude, invert)\u001b[0m\n\u001b[1;32m    277\u001b[0m m \u001b[39m=\u001b[39m listify(magnitude, \u001b[39m4\u001b[39m)\n\u001b[1;32m    278\u001b[0m targ_pts \u001b[39m=\u001b[39m [[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mm[\u001b[39m3\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mm[\u001b[39m1\u001b[39m]], [\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mm[\u001b[39m2\u001b[39m],\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mm[\u001b[39m1\u001b[39m]], [\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mm[\u001b[39m3\u001b[39m],\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mm[\u001b[39m0\u001b[39m]], [\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mm[\u001b[39m2\u001b[39m],\u001b[39m1\u001b[39m\u001b[39m+\u001b[39mm[\u001b[39m0\u001b[39m]]]\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m _do_perspective_warp(c, targ_pts, invert)\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/transform.py:266\u001b[0m, in \u001b[0;36m_do_perspective_warp\u001b[0;34m(c, targ_pts, invert)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[39m\"\u001b[39m\u001b[39mApply warp to `targ_pts` from `_orig_pts` to `c` `FlowField`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    265\u001b[0m \u001b[39mif\u001b[39;00m invert: \u001b[39mreturn\u001b[39;00m _apply_perspective(c, _find_coeffs(targ_pts, _orig_pts))\n\u001b[0;32m--> 266\u001b[0m \u001b[39mreturn\u001b[39;00m _apply_perspective(c, _find_coeffs(_orig_pts, targ_pts))\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/fastai/vision/transform.py:247\u001b[0m, in \u001b[0;36m_find_coeffs\u001b[0;34m(orig_pts, targ_pts)\u001b[0m\n\u001b[1;32m    245\u001b[0m B \u001b[39m=\u001b[39m FloatTensor(orig_pts)\u001b[39m.\u001b[39mview(\u001b[39m8\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m    246\u001b[0m \u001b[39m#The 8 scalars we seek are solution of AX = B\u001b[39;00m\n\u001b[0;32m--> 247\u001b[0m \u001b[39mreturn\u001b[39;00m _solve_func(B,A)[\u001b[39m0\u001b[39m][:,\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/Projects/lib/python3.11/site-packages/torch/_linalg_utils.py:105\u001b[0m, in \u001b[0;36msolve\u001b[0;34m(input, A, out)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msolve\u001b[39m(\u001b[39minput\u001b[39m: Tensor, A: Tensor, \u001b[39m*\u001b[39m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, Tensor]:\n\u001b[0;32m--> 105\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    106\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis function was deprecated since version 1.9 and is now removed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`torch.solve` is deprecated in favor of `torch.linalg.solve`. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    108\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`torch.linalg.solve` has its arguments reversed and does not return the LU factorization.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    109\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo get the LU factorization see `torch.lu`, which can be used with `torch.lu_solve` or `torch.lu_unpack`.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    110\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX = torch.solve(B, A).solution \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    111\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mshould be replaced with:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    112\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mX = torch.linalg.solve(A, B)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    113\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This function was deprecated since version 1.9 and is now removed. `torch.solve` is deprecated in favor of `torch.linalg.solve`. `torch.linalg.solve` has its arguments reversed and does not return the LU factorization.\n\nTo get the LU factorization see `torch.lu`, which can be used with `torch.lu_solve` or `torch.lu_unpack`.\nX = torch.solve(B, A).solution should be replaced with:\nX = torch.linalg.solve(A, B)"
     ]
    }
   ],
   "source": [
    "# Rest of your code\n",
    "train_image_list = ImageList.from_df(df=data_df, path=root_path, cols='image_path').split_by_idxs(\n",
    "    (data_df[data_df['dataset_type']=='train'].index),\n",
    "    (data_df[data_df['dataset_type']=='val'].index)).label_from_df(cols='category')\n",
    "test_image_list = ImageList.from_df(df=data_df[data_df['dataset_type'] == 'test'], path=root_path, cols='image_path')\n",
    "\n",
    "data = train_image_list.transform(get_transforms(), size=224).databunch(bs=128).normalize(imagenet_stats)\n",
    "data.add_test(test_image_list)\n",
    "data.show_batch(rows=3, figsize=(8,8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
